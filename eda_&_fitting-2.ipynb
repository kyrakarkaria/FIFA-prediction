{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sag0DS3uu98q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df17=pd.read_csv('FIFA17_official_data.csv')\n",
        "df17['fifa_version'] = '17'\n",
        "df18=pd.read_csv('FIFA18_official_data.csv')\n",
        "df18['fifa_version'] = '18'\n",
        "df19=pd.read_csv('FIFA19_official_data.csv')\n",
        "df19['fifa_version'] = '19'\n",
        "df20=pd.read_csv('FIFA20_official_data.csv')\n",
        "df20['fifa_version'] = '20'\n",
        "df21=pd.read_csv('FIFA21_official_data.csv')\n",
        "df21['fifa_version'] = '21'\n",
        "df22=pd.read_csv('FIFA22_official_data.csv')\n",
        "df22['fifa_version'] = '22'\n",
        "df23=pd.read_csv('FIFA23_official_data.csv')\n",
        "df23['fifa_version'] = '23'\n",
        "dfs = []\n",
        "dfs.append(df17)\n",
        "dfs.append(df18)\n",
        "dfs.append(df19)\n",
        "dfs.append(df20)\n",
        "dfs.append(df21)\n",
        "dfs.append(df22)\n",
        "dfs.append(df23)\n",
        "\n",
        "\n",
        "master_df = pd.concat(dfs, join='outer', sort=False)\n",
        "\n",
        "\n",
        "print(\"Shape of the combined dataframe:\", master_df.shape)\n",
        "master_df.head()"
      ],
      "metadata": {
        "id": "JX6Wi82hFzid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(master_df.columns)"
      ],
      "metadata": {
        "id": "j-xS1JH6GAca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.info()"
      ],
      "metadata": {
        "id": "GsbCiq-DIQs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.isnull().sum()"
      ],
      "metadata": {
        "id": "bOZraTW_iDdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.isnull().sum()/master_df.shape[0]*100"
      ],
      "metadata": {
        "id": "ya8JgmsfjwM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "irLoU_hfkUTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.isnull().sum()/master_df.shape[0]*100\n"
      ],
      "metadata": {
        "id": "U-W1IafKk02O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df=master_df.drop(columns=['Loaned From', 'Marking', 'DefensiveAwareness', 'Kit Number'])"
      ],
      "metadata": {
        "id": "76QWs5xmk3fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "HfzDfFExmT7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in master_df.select_dtypes(include=['object']).columns:\n",
        "    print(i)\n",
        "    print(master_df[i].value_counts())"
      ],
      "metadata": {
        "id": "xsp55FjbmmXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.describe().T"
      ],
      "metadata": {
        "id": "EPrIuldPnc-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.describe(include='object').T"
      ],
      "metadata": {
        "id": "IZ2zvfc2oJeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Reset the index to handle potential duplicate indices after concatenation\n",
        "master_df = master_df.reset_index(drop=True)\n",
        "\n",
        "for i in master_df.select_dtypes(include=['number']).columns:\n",
        "    sns.histplot(data=master_df,x=i)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "g7A1JAiQot8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Reset the index to handle potential duplicate indices after concatenation\n",
        "master_df = master_df.reset_index(drop=True)\n",
        "\n",
        "for i in master_df.select_dtypes(include=['number']).columns:\n",
        "    sns.boxplot(data=master_df,x=i)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Y_ZfxFimpodZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.select_dtypes(include=['number']).columns\n"
      ],
      "metadata": {
        "id": "5zkiOJm1qhGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in ['Age', 'Potential', 'Special',\n",
        "       'International Reputation', 'Weak Foot', 'Skill Moves', 'Jersey Number',\n",
        "       'Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys',\n",
        "       'Dribbling', 'Curve', 'FKAccuracy', 'LongPassing', 'BallControl',\n",
        "       'Acceleration', 'SprintSpeed', 'Agility', 'Reactions', 'Balance',\n",
        "       'ShotPower', 'Jumping', 'Stamina', 'Strength', 'LongShots',\n",
        "       'Aggression', 'Interceptions', 'Positioning', 'Vision', 'Penalties',\n",
        "       'Composure', 'StandingTackle', 'SlidingTackle', 'GKDiving',\n",
        "       'GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes']:\n",
        "       sns.scatterplot(data=master_df,x=i,y='Overall')\n",
        "       plt.show()"
      ],
      "metadata": {
        "id": "cIHJ2eihrZaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.select_dtypes(include=['number']).corr()"
      ],
      "metadata": {
        "id": "Xh0l8Cf_safE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "sns.heatmap(master_df.select_dtypes(include=['number']).corr(),annot=True)"
      ],
      "metadata": {
        "id": "NW9gNR-stCaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df=master_df.drop(columns=['ID','Name','Photo','Flag','Club Logo','Jersey Number','Real Face', 'Contract Valid Until'])"
      ],
      "metadata": {
        "id": "fadDiiFouP6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.isnull().sum()/master_df.shape[0]*100"
      ],
      "metadata": {
        "id": "hWLlmwIKvqNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.info()"
      ],
      "metadata": {
        "id": "RaOZcwFi6pQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df[['Value', 'Wage']].head()"
      ],
      "metadata": {
        "id": "V7Y1bOD2-pfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_currency_robust(value):\n",
        "    if isinstance(value, str):\n",
        "        if value.strip() in ['-', '', 'N/A']:\n",
        "            return np.nan\n",
        "        val_cleaned = value.lower().replace('€', '')\n",
        "        try:\n",
        "            if 'm' in val_cleaned:\n",
        "                return float(val_cleaned.replace('m', '')) * 1000000\n",
        "            elif 'k' in val_cleaned:\n",
        "                return float(val_cleaned.replace('k', '')) * 1000\n",
        "            else:\n",
        "                return float(val_cleaned)\n",
        "        except ValueError:\n",
        "            return np.nan\n",
        "    return value\n",
        "\n",
        "master_df['Value'] = master_df['Value'].apply(standardize_currency_robust)\n",
        "master_df['Wage'] = master_df['Wage'].apply(standardize_currency_robust)\n",
        "\n",
        "\n",
        "\n",
        "print(master_df[['Value', 'Wage']].head())\n",
        "\n",
        "\n",
        "print(master_df[['Value', 'Wage']].dtypes)"
      ],
      "metadata": {
        "id": "iJnPzbnEC9hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def standardize_height(height):\n",
        "\n",
        "    if isinstance(height, str):\n",
        "        if \"'\" in height or '\"' in height:\n",
        "\n",
        "            try:\n",
        "                feet, inches = height.replace('\"', '').split(\"'\")\n",
        "                return (int(feet) * 30.48) + (int(inches) * 2.54)\n",
        "            except ValueError:\n",
        "                return np.nan\n",
        "        elif \"cm\" in height:\n",
        "\n",
        "            return float(height.replace(\"cm\", \"\"))\n",
        "        else:\n",
        "\n",
        "            try:\n",
        "                return float(height)\n",
        "            except ValueError:\n",
        "                return np.nan\n",
        "    return height\n",
        "\n",
        "def standardize_weight(weight):\n",
        "\n",
        "\n",
        "    if isinstance(weight, str):\n",
        "        weight = weight.lower()\n",
        "        if \"lbs\" in weight:\n",
        "\n",
        "            return float(weight.replace(\"lbs\", \"\")) * 0.453592\n",
        "        elif \"kg\" in weight:\n",
        "\n",
        "            return float(weight.replace(\"kg\", \"\"))\n",
        "        else:\n",
        "\n",
        "            try:\n",
        "                num_weight = float(weight)\n",
        "\n",
        "                if num_weight > 120:\n",
        "                    return num_weight * 0.453592\n",
        "                else:\n",
        "                    return num_weight\n",
        "            except ValueError:\n",
        "                return np.nan\n",
        "    return weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "master_df['Height'] = master_df['Height'].apply(standardize_height)\n",
        "master_df['Weight'] = master_df['Weight'].apply(standardize_weight)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(master_df[['Height', 'Weight']].head())\n",
        "\n",
        "print(\"\\n--- New Data Types ---\")\n",
        "print(master_df[['Height', 'Weight']].dtypes)"
      ],
      "metadata": {
        "id": "oeJ9O9jaDPAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.info()"
      ],
      "metadata": {
        "id": "9GpACTnLD7Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(master_df.select_dtypes(include=['object']).nunique().sort_values())\n"
      ],
      "metadata": {
        "id": "Iq5cFOp0EArS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "master_df['Release Clause'] = master_df['Release Clause'].apply(standardize_currency_robust)\n",
        "\n",
        "print(master_df['Release Clause'].dtype)"
      ],
      "metadata": {
        "id": "J4OE4hYLEkwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df['Joined']"
      ],
      "metadata": {
        "id": "XD7J_X88FGr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df['fifa_version'] = pd.to_numeric(master_df['fifa_version'], errors='coerce')\n",
        "master_df['Joined_Date'] = pd.to_datetime(master_df['Joined'], errors='coerce')\n",
        "master_df['Snapshot_Date'] = pd.to_datetime('20' + (master_df['fifa_version'] - 1).astype(str) + '-08-01')\n",
        "time_difference = master_df['Snapshot_Date'] - master_df['Joined_Date']\n",
        "master_df['Days_of_Experience'] = time_difference.dt.days\n",
        "\n",
        "\n",
        "\n",
        "master_df['Days_of_Experience'].fillna(master_df['Days_of_Experience'].median(), inplace=True)\n",
        "master_df['Days_of_Experience'] = master_df['Days_of_Experience'].apply(lambda x: max(x, 0))\n",
        "master_df['Days_of_Experience'] = master_df['Days_of_Experience'].astype(int)\n",
        "\n",
        "\n",
        "print(\"\\n--- Sample of the New 'Days_of_Experience' Column ---\")\n",
        "print(master_df[['fifa_version', 'Days_of_Experience']].head())\n",
        "\n",
        "master_df.drop(columns=['Joined_Date', 'Snapshot_Date', 'Joined'], inplace=True, errors='ignore')\n",
        "\n"
      ],
      "metadata": {
        "id": "CBRJ4CSdIbTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(master_df.select_dtypes(include=['object']).nunique().sort_values())"
      ],
      "metadata": {
        "id": "GZM4GrODIceq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "y = master_df['Overall']\n",
        "\n",
        "X = master_df.select_dtypes(include=np.number).drop(columns=['Overall'])\n",
        "\n",
        "print(f\"Using {X.shape[1]} numerical features to predict 'Overall'.\")\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "MT6r5oMtIn9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "8FS9iS_zLeAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n"
      ],
      "metadata": {
        "id": "LSXZ6iuCMd8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {
        "id": "YxjXR5frMpbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"\\n--- Baseline Model Evaluation ---\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"R-squared (R²): {r2:.2f}\")"
      ],
      "metadata": {
        "id": "wmXCz8LSMwWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "y = master_df['Overall']\n",
        "\n",
        "features_to_drop = [\n",
        "    'Overall',\n",
        "    'Best Overall Rating',\n",
        "    'Special',\n",
        "    'Potential',\n",
        "    'Value',\n",
        "    'Wage',\n",
        "    'Release Clause'\n",
        "temp_df = master_df.drop(columns=features_to_drop, errors='ignore')\n",
        "\n",
        "X = temp_df.select_dtypes(include=np.number)\n",
        "\n",
        "\n",
        "print(f\"FINAL FEATURE SET: Using {X.shape[1]} 'true skill' numerical features.\")\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-l34DfXP3l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "\n",
        "X_test_imputed = imputer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "xdcK7I-mP90D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test_imputed)"
      ],
      "metadata": {
        "id": "fgkDpP6DQoCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "\n",
        "\n",
        "model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "eZy95qcNQwT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Make predictions on the preprocessed test data\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the performance metrics\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"\\n--- Baseline Model Evaluation ---\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"R-squared (R²): {r2:.2f}\")"
      ],
      "metadata": {
        "id": "KIeoR6d0QxHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
        "\n",
        "# 2. Train the model (assuming you have your preprocessed data)\n",
        "print(\"Training XGBoost model...\")\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# 3. Make predictions and evaluate\n",
        "predictions = xgb_model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(f\"\\nXGBoost MAE: {mae:.2f}\")\n",
        "print(f\"XGBoost R²: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "G_nKIRhGVzQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "_DJai_kkY0cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "top_50_clubs = master_df['Club'].value_counts().nlargest(50).index\n",
        "master_df['Club_Grouped'] = master_df['Club'].apply(lambda x: x if x in top_50_clubs else 'Other')\n",
        "\n",
        "\n",
        "top_50_nationalities = master_df['Nationality'].value_counts().nlargest(50).index\n",
        "master_df['Nationality_Grouped'] = master_df['Nationality'].apply(lambda x: x if x in top_50_nationalities else 'Other')\n",
        "\n",
        "\n",
        "top_5_body_types = master_df['Body Type'].value_counts().nlargest(5).index\n",
        "master_df['BodyType_Grouped'] = master_df['Body Type'].apply(lambda x: x if x in top_5_body_types else 'Other')\n"
      ],
      "metadata": {
        "id": "fzD8cXKlb7uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = master_df['Overall']\n",
        "\n",
        "\n",
        "features_to_drop = [\n",
        "    'Overall','Best Overall Rating', 'Special', 'Potential', 'Value', 'Wage', 'Release Clause','Club', 'Nationality', 'Body Type'\n",
        "]\n",
        "\n",
        "\n",
        "X = master_df.drop(columns=features_to_drop, errors='ignore')\n",
        "print(master_df.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SAS5eTjCb_-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_cols = X_train.select_dtypes(include=np.number).columns\n",
        "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n"
      ],
      "metadata": {
        "id": "4jh7qNalcD2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = RandomForestRegressor(n_estimators=10, random_state=42,max_depth=10, n_jobs=-1)\n",
        "\n",
        "full_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                ('regressor', model)])\n",
        "\n",
        "full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "predictions = full_pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "eo3NifpLcLK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"R-squared (R²): {r2:.2f}\")\n",
        "\n",
        "print(f\"Baseline Model MAE (numerics only): 1.25\")\n",
        "print(f\"Upgraded Model MAE (all features): {mae:.2f}\")"
      ],
      "metadata": {
        "id": "6omjk9ERcPge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "24HWYcXWe70l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}